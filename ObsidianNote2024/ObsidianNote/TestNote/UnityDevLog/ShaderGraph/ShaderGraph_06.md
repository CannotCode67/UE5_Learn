Using vertex displacement to simulate wind through shader is a much better choice than using a mesh with animation, or physics simulation. 

For detail, watch these two videos.
![[UnityDevLog/ShaderGraph/GetImage (1).png]]
![[UnityDevLog/ShaderGraph/GetImage (2).png]]Brackey's method but using vertex color info (the mesh has black at the bottom and gradually gets to white on its way to the top)
![[UnityDevLog/ShaderGraph/GetImage (3).png]]
We check the flow backward, so from the end first. Vertex position slot in master node only takes in Vector3 value in object space, I guess it takes in Vector3 value in other space as well, just doesn't work properly. A lerp node with three inputs, the A is the original static vertex position, the B is the modified vertex position, and the C is the condition to decide whether this part apply A or apply B and to what extent. Here we use vertex color in RGB value, matching the C slot needs a vector3 value. The modified vertex position info comes from a transform node which converts the vertex position in world space into the vertex position in object space. Here we see the position node in world space get split using a split node. Although the outputs in split node are R, G, B, A, we actually gets x position in R, y position in G, and z position in B. What do we get in A? I don't know, maybe nothing, since the position only outputs a vector3 value. And the G and B outputs go directly into the G and B slots in the combine node without any change. So only the x value of the vertex position of this mesh gets modified. Through inspecting the mesh in isometric view, it turns out because only the x value of vertex position info has changes, it would make the mesh only have movement along x axis, no matter how we adjust the windMovement property, well no movement at all if windMovement has (0, 0) as value. I think we can fix this just making the z value(B) to have changes as well. The x value goes into the add node, so we need to figure out where this change comes from. Multiple node has A input times B input which is the windStrength float for control. The subtract node has A input minus B which is 0.5. From gradient noise node, we can see most of the time, we get white value and grey value, and they are values ranging from 0 to 1. The vertex would only move at one direction with only positive variables, but that's not what we want unless the mesh is simulating a situation where a strong wind going strictly one direction. We want the vertex goes back and forth. So it needs positive and negative values both appearing often. So subtracting 0.5 would makes most values ranging from 0.5 to -0.5. How this gradient noise node takes in a UV and scale factor then outputs a vector1 value? My understanding is the noise is s procedurally generated 2D map. It needs a 2D surface to map on, so it needs a UV space which is a 2D space. The scale input controls the size ratio between this 2D space and this 2D noise map. The output is the overall sum of all the greyscale value in this 2D space? Really not sure. The UV comes from a tilling and offset node. We use time node and a windMovement (vector2 value) to multiply together giving the offset value( vector2). It makes sense the offset needs a vector2 value since it is a 2D space. Position node outputs a vector3 value and it is plugged in the UV slot  which requires a vector2 value, so it is using only x and y value. However, how this vertex position value becomes a UV or a 2D space is not understood to me by now. Maybe the position node outputs all the position values for every vertex of this mesh, but it doesn't show in the preview window of the node. If that's the case, how this info generate a 2D space? Not a clue yet. 

Position node description from Unity's manual: 

Position node in shader graph outputs the access of the mesh's vertex position or fragment position in space we choose. 

Now, we examine the Unity's method. We also use the same vertex color info like we did in Brackey's method.![[UnityDevLog/ShaderGraph/GetImage (4).png]]
We also check this flow backward. It is a lerp node using the original static vertex position coming out of a Position node (object space) as A input. B input is coming out of another lerp node, but we know this is the modified vertex position info. It use a gradient noise node as filtering condition. In Unity's manual, it describes the three inputs of the lerp node have value type of dynamic vector, meaning they can take in vector1, vector2, and vector3. But I guess A and B would have to be the same vector type to be able to replace each other interchangeably. While the filtering condition (C input) can use any vector type having no regard of A and B's vector type. The gradient noise node has the noise scale property for scale input, and UV input from the tiling and offset node. The UV input of the tiling and offset node is default, I guess it just needs any 2D surface to map the noise map. The offset takes in a vector2 value, but it is getting a vector1 output from multiply node. So, it auto convert the vector1 value into vector2 by assigning the y value to be the same as the x value. Multiply node also takes in dynamic vector type, and because both of its input are vector1 type, so it is outputting a vector1 value. Here, it just needs the noise value, so which way it goes doesn't matter? Move on to the second last lerp node. It has a static vertex position from a position node (object space) and the modified one. It uses vertex color info as filtering condition here. So, it is applying more movement the higher it gets. This transform node converts world space vertex position info to object space, so before this node, the vertex position info is in world space. We get the add node adding the static position vertex position (the base) coming out of a position node (world space) and the variations from a split and combine treatment. This treatment remaps the y value(G) to z value(B), so the changes in x value is retained, and changes in y value is now changes in z value. It makes sense because we only want movement from x and z direction. We don’t want the vertex goes up and down, so no changes in y value. But why do we have the changes stored in y values before? We check the multiply node, we use a vector 2 to control the wind direction and multiply it with some kind of magnitude of changes, I guess. Vector2 value has x value and y value automatically, so we need to remap this y value to z value, otherwise, we need to use a vector3 value with y value set to zero, then we don’t need the split and combine treatment. And it does work, when we adjust the direction property, the mesh's movement change direction accordingly, unlike the one in Brackey has movement only along x axis. Now, the magnitude of changes.![[UnityDevLog/ShaderGraph/GetImage (5).png]]
The add, multiply, and multiply, and subtract nodes are a series of mathematical function to limit the displacement in a spherical direction, that's what the video said. I don't really understand how it work in math. Before that, we have a multiply node with B input as a bunch of modification of the cosine time output. We know cosine time output varies from -1 to 1, and it uses the bendStength property along with a multiply node and divide node of 100 to control the final outcome, making it very small. Like when bendStrength is 1, it has outputs vary from -1/100 to 1/100. The A input of the multiple node comes from the split node's G output. And the split node is splitting the position node (object space) into R (x value), G (y value), B(z value). We only use the y value is because we want to bend the vertex position with y axis. Using a position node (object space) and split its G value to a preview node. We can see vertex on the upper part has value above zero and equal to 1 when reaching the top, and vertex in the lower half has value below zero and equal to -1 when reaching the bottom. So, when you apply bend force (a magnitude) bigger than 1, the upper would get bigger, and the lower would get smaller. With a direction like x axis, bigger means going to right, and smaller means going to left. So, upper vertices go to right and lower vertices go to left, we get a bending along y axis. And that's correct, since we don't want any up and down movement. This bending, if we inspect it in the preview, looks very much like wave on water surface. Similar technique should be able to be utilized for water shader as well. However, for this specific mesh, the wheat head and the stalk are not vertex wielded together. And when the movement applies to the mesh, the wheat head and the stalk are not moving at the same pace. Brackey's method does not have this issue.