-----continue from the end of FSM & states note
That's all the states now. But we are not done. Remember that sensor system we keep mentioning? It is the time for us to go there. The reason I put the sensor system here because the sensor system is integrated mainly to work with the FSM. It is barely used outside of the state machine. The sensor system contains three parts: the ai sensor class (MonoBehaviour), the ai sensor memory class (inherits from nothing), and the ai sensor target class (MonoBehaviour).

The first one we look at is the ai sensor class. We see a timer technique to control the invoking of a method called Scan() in the Update loop. As the name suggests, it should scan things. Inside, we first see the Physics.OverlapSphereNonAlloc() method. This method is taking in a position as the origin, and a float as the radius to simulate a sphere. By default, any collider inside or in contact with this simulated sphere would be detected. But we can still pass a layermask and a QueryTriggerInteraction as additional parameters to specify which layers to detect and what type of collider to detect, trigger, non-trigger, or both. The name has NonAlloc, so it is the non allocating version of the method, meaning we need to provide a proper collection as a parameter to output the detected colliders. Our example uses array, but maybe some other collections can work as well, haven't got time to look into it. Then, we have a list of objects cleaned up using Clear(). Apparently, we are refreshing the list everytime we call Scan(). The Physics.OverlapSphereNonAlloc() returns the number of colliders detected. So we do a for loop using that number as limit, and inside the for loop, we inspect each collider's attached game object, using a method called IsInSight(), if it returns true, then we add the game object into our list. Now, before we take a look at this IsInSight() method, we first need to understand the sensor in our design. The sensor in our design has a wedge shape. What is a wedge? It is a object with one side being sharp and pointy and the other side being flat and round. Well, this seems to blur the idea even more. Just look at the picture.
![[FSM-codeSnippet02.png]]
The blue shape in the picture is actually created by a method called CreateWedgeMesh() in the ai sensor class. It is a visual approximation of the area where our sensor can detect. We will come back to the CreateWedgeMesh() method later. Now, we know the shape of the sensor, we can understand the IsInSight() much easily. Inside the method, first we get three Vector3 values, the ai character's position, the passed in object's position, and the object direction obtained by just subtracting the object's position by ai character's position. Then, we write three checks. The first check is whether the object direction's y value is less than -1 or bigger than the sensor height, if so return false. The origin of the sensor is the transform of the ai character, which is what we pass into the Physics.OverlapSphere method as origin. In our example, it locates around in the middle of both feet. The sensor height is how much the shape goes up. If the y value is bigger than that, meaning the object is above the sensor, so it should not be considered detected. Or the y value is less than -1, meaning the object is below the sensor, so it is not considered detected either. You may wonder why not using zero. Well, the problem is the ai character's transform might not be at the same horizontal level as the object's transform due to many factors like collider's properties or simply just we don't place the object on the ground. So, -1 gives us some room for this inaccuracy, but it is a temporary value that works in our example, it might be modified to fit a different design. Okay, now the second check is if the angle between object direction and ai character's transform.forward is bigger than our angle limit, then return false. Notice, here we set the object direction's y value to be zero, because you will get an accurate angle that fits our need, only if both directions are on the same plane. We use Vector3.Angle() to get the angle between. This method always returns a value in range of 0 to 180 in degrees, so in situations where an object is 30 degree to the left or 30 degree to the right, the method will return 30 degrees regardlessly. The third check is to fire a Physics.Linecast(), if it hits anything, we return false. This checks if there is any obstacle in between blocking the object. We pass the line origin using the ai character's position with y equal to half of the sensor height, and we pass the line target using the object's position with y equal to that as well. This ensure the linecase is fired in the middle to get a better result. If the execution gets to the bottom of the method, meaning it passes all those checks, we return true.

The overall logics is to use Physics.OverlapSphere to detect the colliders, then use the IsInSight() method to judge each collider attached game object to see if it should be considered detected. If so, we add that object to our list. After each Scan(), we have a new list of objects considered detected, because we clean up the list in the beginning of the Scan() method, remember? A big catch is Physics.OverlapSphere and other methods under Physics class really, they don't work with the Unity built-in character controller. Even though we know the character controller uses a capsule collider underneath, it cannot be detected by the Physics methods. That's why we mention giving the player character a trigger collider at top level even we are using character controller to handle movement. By the way, the laymask should exclude the ragdoll colliders, as we don't want a character to be detected multiple times.

Okay, what's left is the CreateWedgeMesh() in this class. I don't want to mention it as it is not really related to our in game logics here, but creating a visual approximation helps a lot when developing and debugging the sensor. The value of studying it is to know how to create tools to help development. The way to create a visual approximation is to create a mesh through code, that way, the mesh would change based on our fields, which means the mesh can adopt to our need without going back to maya and remodeling it. Then, apply a material with alpha value to get the transparent look for the sensor visualization. Now, going Inside the method, we first create a instance of the Mesh class. This is the class Unity used for mesh, and it has a vertices property and a triangles property that we can assign. After assigning those, we can call its RecalculateNormals() method to generate the mesh. A vertex is just a Vector3 value, and the vertices property is just an array of Vector3. The triangles property is an array of int. The order of vertices added shoulld be relevant to the normal direction, and no identical vertex should be added multiple times into the array. Honestly, this part of getting and assigning vertices in our example is not really correct as it ignores many rules. It does its thing okay, but that's not the right way to do it. I suggest research more on this subject to know the ins and outs of what is going on. If we really need the code fast, we can go check the script. Anyway, the CreateWedgeMesh() method is invoked in a method called OnValidate(), which is a editor-only function called by Unity whenever the script is loaded and a value changes in the inspector. So that we can see the mesh and modify it without going into play mode. One more thing to actually run this script in editor mode, we need to put the `[ExecuteInEditMode]` attribute on top of the class. To render the mesh and facilitate the development further, we implement the OnDrawGizmos() method. We use Gizmos.DrawMesh() to render the mesh, and Gizmos.DrawWireSphere to draw a wire sphere representing the Physics.OverlapSphere, and Gizmos.DrawSphere to draw one sphere for each detected collider, and one sphere in different color for each object considered detected.

Finally, we get through the ai sensor class. Not many lines of codes, but a lot details to cover. Next, we move on to the ai sensor memory class. Before that, we talk about how they work together. The ai sensor class basically has a list of objects considered detected, and refreshing the list in certain frequency in Update loop. The ai sensor memory class has a method called UpdateSensor() taking in the ai sensor object as parameter. This method loads the objects in that list into a dictionary where the object is the key, and a boolean is the value. The first load of an object always has a value of true. If the object is already in the dictionary, we set the corresponding value to true. In concept, having a true value means this object is detected by the latest Scan() of the sensor. When does an object gets a value of false? In the beginning of the UpdateSensor() method, we iterate through the dictionary to give all elements a value of false, so unless an object keeps being detected, it would get a value of false the next time this method is called. By now, we have a dictionary indicating the detected objects and its latest status of being detected or not. Then, the last part of the UpdateSensor() method, is to iterate through the dictionary, if the object's latest status is being detected, then we pass that object and the snesor into a method called RefreshMemory. Otherwise, we remove the object from the dictionary. So an object would not live in the dictionary once it gets a false value. In other words, once an object is not detected in the latest scan, we don't hold on to it. But don't worry, if it gets detected later, it will be loaded into the dictionary again. Here comes the next part. The dictionary is merely an intermediate container to update the objects detected in the last two scans. The ai sensor memroy class actually uses another class called ai memory to store the object information for longer term. The ai memory class is defined in the same script but outside the ai sensor memory class. You probably can define it inside as a sub class like Bullet class. The ai memory class acts as a container for a bunch of variables, and that's it, no method, well besides a slightly complicated getter for one of its properties.
![[FSM-codeSnippet03.png]]
The ai sensor memory class has a list of ai memory objects. Now back to where we left off, the end of the UpdateSensor() method, we send objects with true value into a method called RefreshMemory(). Inside this RefreshMemory() method, we first invoke a method called FetchMemory() which takes in a game object and return an ai memory object. Then, we update this ai memory object's fields with the passed in object so that it is updated. Now, FetchMemory() method is simple, it checks if the list of ai memory objects contains a memory with gameObj field equalling to the passed in object, if so, simply returns that ai memory object. Otherwise, we create a new ai memory object and add that to the ai memory object list. So, to sum it up, the RefreshMemory() asks the FetchMemory() method to give us an ai memory object, which might be newly created or already existed in the list of ai memory objects, but doesn't matter. Once we have this ai memory object, we update its fields using the parameter object. Then, the ai sensor memory class now have a list of ai memory objects, updated. But what about the ones not updated? Objects that were detected, sent to the dictionary, then sent to create ai memory objects. What happen to those ai memory objects? In the same class, there is a method called ForgetMemory() takes in a float. Inside this method, we implement the logics to remove ai memory objects if they meet certain conditions. For example, the float parameter is used to compared with ai memory object's Age property. If the Age property is bigger than the float parameter, then the ai memory object is removed due to the fact that there has been a while since the last time we detect the corresponding game object. We can also remove the ai memory object which has a corresponding game object that is already destroyed, using `memories.RemoveAll(m => !m.gameObj)`. Now we are done with he ai sensor memory class.

The last one is the ai sensor target class, which is the simplest of the three. It is responsible for creating an instance of the ai sensor memory class, and in Update loop, invoking the UpdateSensor() and ForgetMemory() methods on that instance. So that the ai sensor memory object has its list of ai memory updated every frame. Lastly, we call a method in this class, EvaluateScores(). Sorry to interrupt again, this ai sensor target class has a field of ai memory, and its name is targetMemory. Should be obvious, the EvaluateScores() would iterate through the list of ai memory do whatever it needs to give each of them a score, and the one with highest score or lowest score would be picked as the target memory. The method to give a score is called CalculateScore() taking in an ai memory object naturally. Inside, we have three scores calculated, and return the sum of them. One is the distance score, where we divide the memory's distance by the sensor's distance. So the memory's distance is the distance between object and the ai character, and the sensor's distance is the max distance we can detect, basically it is the radius of the Physics.OverlapSphere. We are getting a normalized value as the max is one and min is zero, but doing it this way would mean the most away object would have the highest score, and if we are picking the highest one for the best target to attack, then it doesn't make much sense. So we can use one to subtract them to inverse the result. For the other two, we are using similar technique to get the score. For angle, we have the angle limit, and for Age, we have a memory time Span. To fine tune the final result, we add a weight for each score, so that we can prioritize our factors the way we want. Also we can implement any additional logics to contribute the final score. Like our example, we check if we have any weapon, and if not and the ai memory corresponding object is in the layer of pickup, then this ai memory's score would get a bonus.

To make the target memory stand out, we can implement the OnDrawGizmos() to draw a sphere to the target memory object with a special color.

Till now, the sensor system is finished studied. With the ai sensor memory and ai sensor target added on top of the ai sensor class, the sensor system can not only detect objects, but also apply logics to prioritize objects when multiple ones are detected. Because ai memory can live for a longer term, ai character now still has access to those information even though the object is out of the sensor currently. And if it decides to pick that as the target, it is using the information obtained by last scan, not the constantly updated information through reference. All of these make the ai character behave as if it can actually remember things and have some level of intelligence to apply some sort of tactics.

Still, there are rooms to improve. One of which is to get rid of the intermediate container of dictionary. It seems kind of redundant. In the example, we check object's layer to see if it belongs to pickup or character or player. Only if it does, we would check for its existing in the dictionary and give it a value of true. This job can actually be done in the Physics.OverlapSphere method, where we pass in a layermask to denote which layers to detect. If an object belongs to a layer that is not supposed to be detected, then its collider would not get picked up by the OverlapSphere, and it would not go to the list of objects at the first place. As such, we don't need to check the layer as we iterate through the list to load objects into dictionary. But the technique is worth mentioning. When we check for layer, gameObject.layer is an int value, the indexer for this particular layer. We can turn our layer name into its corresponding indexer by `int layer1 = LayerMask.NameToLayer("Character")`. Another technique to mention is when we want to iterate through dictionary, we cannot use `foreach (var ele in dictionary)` `{ele.key = something; ele.value = something}` to do it. Dictionary in C# doesn't allow us to iterate through it by elements. Instead, we can use this `foreach (var key in dictionary.Keys.ToList()) {dictionary[key] = something}` to perform our iteration.